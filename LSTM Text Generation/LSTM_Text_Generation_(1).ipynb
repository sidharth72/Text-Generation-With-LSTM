{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGjEO_kXLFdA",
        "outputId": "0ad4c0b5-f4a4-47ef-f072-eec1eb61f149"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "Hgro_IDk2H5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with open('/content/drive/MyDrive/Natural-Language-Processing/train.en', 'r') as f:\n",
        "    sentences = f.readlines()"
      ],
      "metadata": {
        "id": "dk0h0nw1ADRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = sentences[:3000]"
      ],
      "metadata": {
        "id": "KinIPrhP3lzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def preprocess(sentence):\n",
        "    sentence = sentence.lower()\n",
        "    sentence = re.sub(r'\\d+', '', sentence)\n",
        "    sentence = re.sub(r'[^a-zA-Z\\s]', '', sentence)\n",
        "    sentence = sentence.strip()\n",
        "    return sentence\n",
        "\n",
        "sentences = [preprocess(sentence) for sentence in sentences]"
      ],
      "metadata": {
        "id": "eOKBDaueLeOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adjust_sentence_length(sentences, sequence_length):\n",
        "    adjusted_sentences = []\n",
        "    buffer = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "        words = sentence.split()\n",
        "        buffer.extend(words)\n",
        "\n",
        "        while len(buffer) >= sequence_length:\n",
        "            adjusted_sentences.append(' '.join(buffer[:sequence_length]))\n",
        "            buffer = buffer[sequence_length:]\n",
        "\n",
        "    if buffer:\n",
        "        adjusted_sentences.append(' '.join(buffer))\n",
        "\n",
        "    # Post-processing to ensure all sentences are around sequence_length\n",
        "    adjusted_sentences_final = []\n",
        "    for sentence in adjusted_sentences:\n",
        "        words = sentence.split()\n",
        "        if len(words) < sequence_length:\n",
        "            if adjusted_sentences_final:\n",
        "                last_sentence_words = adjusted_sentences_final[-1].split()\n",
        "                if len(last_sentence_words) + len(words) <= sequence_length:\n",
        "                    adjusted_sentences_final[-1] += ' ' + sentence\n",
        "                    continue\n",
        "        adjusted_sentences_final.append(sentence)\n",
        "\n",
        "    return adjusted_sentences_final\n",
        "\n",
        "sentences = adjust_sentence_length(sentences, 20)"
      ],
      "metadata": {
        "id": "v6w90QRgOQGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIH5NAu6OpWt",
        "outputId": "e197887a-c632-4b95-8629-d6d3e06793e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the plot of the movie revolves around the life of two cancer patients kizie and manny the same as on',\n",
              " 'the stone oommen chandy mullappally ramachandran ramesh chennithala and pk many were arrested and jailed what has happened they are',\n",
              " 'doing politics the back houses a rear camera was it sometime during his prehuman existence at his birth as a',\n",
              " 'human at his baptism or upon his being resurrected they didnt talk the driver immediately informed the police they have',\n",
              " 'subsequently been expelled from the party to that end we can reflect on some past examples of courage it was',\n",
              " 'the first time something like that was happening in my life i will be sending a letter to the cm',\n",
              " 'in this regard he said the security personnel were caught off guard where is achhe din which way will you',\n",
              " 'go in it became part of the mission san gabriel arcngel and then the rancho san gorgonio he was speaking',\n",
              " 'at the inaugural session of the threeday conference and exhibition titled aurangzeb and dara shukoh a tale of two brothers',\n",
              " 'that is being held at indira gandhi national centre for arts the filming of tovino thomas new film forensic has',\n",
              " 'begun say as for me my lord has guided me to a straight path a right religion the creed of',\n",
              " 'abraham a man of pure faith he was no idolater well anything a threejudge bench led by justice arun mishra',\n",
              " 'was hearing the case if he gives you any trouble hit him they are also restricted from opening new branches',\n",
              " 'and paying dividends what is a missionary i dont have any problem with it it gets snapdragon processor mp rear',\n",
              " 'camera and a mah battery its a big thing that will give you time to reflect on what you read',\n",
              " 'and to let the experience touch your heart he sustained injuries on his neck and hand i can go the',\n",
              " 'incident remains a mystery parish priest fr no she said flatly one example will underline how important this principle is',\n",
              " 'inside the maserati quattroporte gts the upholstery and leather have been updated and it now comes with an inch maserati',\n",
              " 'touch control plus mtc system that sits in the centre of the dashboard say it is he who has scattered',\n",
              " 'you on the earth and it is to him that you shall all be gathered on the day of resurrection']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_vocab_map(d, sentences):\n",
        "    index = 1\n",
        "    for sentence in sentences:\n",
        "        for word in sentence.split():\n",
        "            if word not in d:\n",
        "                d[word] = index\n",
        "                index += 1\n",
        "\n",
        "vocab_mapping = {}\n",
        "generate_vocab_map(vocab_mapping, sentences)"
      ],
      "metadata": {
        "id": "GtaD2ZX27x7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_int_to_text(int_sequences, vocab_map):\n",
        "    # Create a reverse mapping from index to word\n",
        "    reverse_vocab_map = {index: word for word, index in vocab_map.items()}\n",
        "\n",
        "    text_sequences = []\n",
        "    for int_sequence in int_sequences:\n",
        "        text_sequence = []\n",
        "        for token in int_sequence:\n",
        "            if token in reverse_vocab_map:\n",
        "                text_sequence.append(reverse_vocab_map[token])\n",
        "\n",
        "        text_sequences.append(' '.join(text_sequence))\n",
        "\n",
        "    return text_sequences"
      ],
      "metadata": {
        "id": "q3d_j579e7Rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = []\n",
        "\n",
        "def generate_tokens(tokens_list, sentences, vocab_map):\n",
        "    for sentence in sentences:\n",
        "        sentence_tokens = []\n",
        "        for word in sentence.split():\n",
        "            if word in vocab_map:\n",
        "                sentence_tokens.append(vocab_map[word])\n",
        "\n",
        "        tokens_list.append(sentence_tokens)\n",
        "\n",
        "generate_tokens(sequences, sentences, vocab_mapping)"
      ],
      "metadata": {
        "id": "tC_T_Het74OO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEqlRcy48fJO",
        "outputId": "b8cd9be5-005b-4b30-ee3a-7e99458683a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 2, 3, 1, 4, 5, 6, 1, 7, 3, 8, 9, 10, 11, 12, 13, 1, 14, 15, 16],\n",
              " [1,\n",
              "  17,\n",
              "  18,\n",
              "  19,\n",
              "  20,\n",
              "  21,\n",
              "  22,\n",
              "  23,\n",
              "  12,\n",
              "  24,\n",
              "  25,\n",
              "  26,\n",
              "  27,\n",
              "  12,\n",
              "  28,\n",
              "  29,\n",
              "  30,\n",
              "  31,\n",
              "  32,\n",
              "  33],\n",
              " [34,\n",
              "  35,\n",
              "  1,\n",
              "  36,\n",
              "  37,\n",
              "  38,\n",
              "  39,\n",
              "  40,\n",
              "  41,\n",
              "  42,\n",
              "  43,\n",
              "  44,\n",
              "  45,\n",
              "  46,\n",
              "  47,\n",
              "  48,\n",
              "  45,\n",
              "  49,\n",
              "  15,\n",
              "  38],\n",
              " [50,\n",
              "  48,\n",
              "  45,\n",
              "  51,\n",
              "  52,\n",
              "  53,\n",
              "  45,\n",
              "  54,\n",
              "  55,\n",
              "  32,\n",
              "  56,\n",
              "  57,\n",
              "  1,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  1,\n",
              "  61,\n",
              "  32,\n",
              "  62],\n",
              " [63,\n",
              "  64,\n",
              "  65,\n",
              "  66,\n",
              "  1,\n",
              "  67,\n",
              "  68,\n",
              "  69,\n",
              "  70,\n",
              "  71,\n",
              "  72,\n",
              "  73,\n",
              "  16,\n",
              "  74,\n",
              "  75,\n",
              "  76,\n",
              "  3,\n",
              "  77,\n",
              "  42,\n",
              "  41],\n",
              " [1, 78, 79, 80, 81, 69, 41, 82, 83, 84, 7, 85, 86, 87, 88, 38, 89, 68, 1, 90],\n",
              " [83,\n",
              "  91,\n",
              "  92,\n",
              "  93,\n",
              "  94,\n",
              "  1,\n",
              "  95,\n",
              "  96,\n",
              "  26,\n",
              "  97,\n",
              "  98,\n",
              "  99,\n",
              "  100,\n",
              "  101,\n",
              "  102,\n",
              "  103,\n",
              "  104,\n",
              "  105,\n",
              "  86,\n",
              "  106],\n",
              " [107,\n",
              "  83,\n",
              "  42,\n",
              "  108,\n",
              "  109,\n",
              "  3,\n",
              "  1,\n",
              "  110,\n",
              "  111,\n",
              "  112,\n",
              "  113,\n",
              "  12,\n",
              "  114,\n",
              "  1,\n",
              "  115,\n",
              "  111,\n",
              "  116,\n",
              "  93,\n",
              "  41,\n",
              "  117],\n",
              " [48,\n",
              "  1,\n",
              "  118,\n",
              "  119,\n",
              "  3,\n",
              "  1,\n",
              "  120,\n",
              "  121,\n",
              "  12,\n",
              "  122,\n",
              "  123,\n",
              "  124,\n",
              "  12,\n",
              "  125,\n",
              "  126,\n",
              "  38,\n",
              "  127,\n",
              "  3,\n",
              "  8,\n",
              "  128],\n",
              " [69,\n",
              "  101,\n",
              "  54,\n",
              "  129,\n",
              "  48,\n",
              "  130,\n",
              "  131,\n",
              "  132,\n",
              "  133,\n",
              "  134,\n",
              "  135,\n",
              "  1,\n",
              "  136,\n",
              "  3,\n",
              "  137,\n",
              "  138,\n",
              "  139,\n",
              "  140,\n",
              "  141,\n",
              "  30]]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_list = [sequence for sequence in sequences]\n",
        "tokens = [token for word_seq in tokens_list for token in word_seq]\n",
        "\n",
        "tokens[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdKVPxkL8ifm",
        "outputId": "b237b400-ef38-4281-b1b5-8f93920d27af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 1, 4, 5, 6, 1, 7, 3]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequence = []\n",
        "targets = []\n",
        "sequence_length = 20\n",
        "\n",
        "for i in range(len(tokens) - sequence_length):\n",
        "    input_sequence.append(tokens[i:i+sequence_length])\n",
        "    targets.append(tokens[i + sequence_length])"
      ],
      "metadata": {
        "id": "uOLxM0yK-RTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequence[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTzkoB_DCafL",
        "outputId": "6985e229-498b-46e2-80d1-25ae064e3197"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 2, 3, 1, 4, 5, 6, 1, 7, 3, 8, 9, 10, 11, 12, 13, 1, 14, 15, 16],\n",
              " [2, 3, 1, 4, 5, 6, 1, 7, 3, 8, 9, 10, 11, 12, 13, 1, 14, 15, 16, 1],\n",
              " [3, 1, 4, 5, 6, 1, 7, 3, 8, 9, 10, 11, 12, 13, 1, 14, 15, 16, 1, 17],\n",
              " [1, 4, 5, 6, 1, 7, 3, 8, 9, 10, 11, 12, 13, 1, 14, 15, 16, 1, 17, 18],\n",
              " [4, 5, 6, 1, 7, 3, 8, 9, 10, 11, 12, 13, 1, 14, 15, 16, 1, 17, 18, 19]]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fttjFC82Ccrf",
        "outputId": "528ce1cd-9b4b-4545-adfa-4ad5d456e7f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 17, 18, 19, 20, 21, 22, 23, 12, 24]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(input_sequence)\n",
        "y = np.array(targets)"
      ],
      "metadata": {
        "id": "GcEN0d0rCxBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUrQymibC6xr",
        "outputId": "63de1be0-68fe-4e6e-9da3-0afb24ccb5bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   1,    2,    3, ...,   14,   15,   16],\n",
              "       [   2,    3,    1, ...,   15,   16,    1],\n",
              "       [   3,    1,    4, ...,   16,    1,   17],\n",
              "       ...,\n",
              "       [6568, 5568, 6569, ...,  156,  253, 1044],\n",
              "       [5568, 6569, 6570, ...,  253, 1044,   38],\n",
              "       [6569, 6570, 6571, ..., 1044,   38, 2036]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y = to_categorical(y)"
      ],
      "metadata": {
        "id": "umvHHhyxC8jM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ke_xzxr-caVo",
        "outputId": "979af4b1-0948-4436-e7bf-7ea79aeb62bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('/content/drive/MyDrive/Natural-Language-Processing/LSTM_Generator2')"
      ],
      "metadata": {
        "id": "GRC8jTkC1zDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(vocab_mapping) + 1, output_dim=128))\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(LSTM(128))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(units=len(vocab_mapping) + 1, activation='softmax'))\n",
        "\n",
        "model.compile(loss = \"categorical_crossentropy\", optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "A1cJupKcC-Ne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, batch_size = 32, epochs = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JcyVM_XDVpF",
        "outputId": "674c0d68-792b-48a6-bedb-274d1fdeadb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "936/936 [==============================] - 27s 21ms/step - loss: 7.8472 - accuracy: 0.0474\n",
            "Epoch 2/100\n",
            "936/936 [==============================] - 12s 13ms/step - loss: 7.1543 - accuracy: 0.0662\n",
            "Epoch 3/100\n",
            "936/936 [==============================] - 12s 12ms/step - loss: 6.8248 - accuracy: 0.0734\n",
            "Epoch 4/100\n",
            "936/936 [==============================] - 13s 14ms/step - loss: 6.5465 - accuracy: 0.0841\n",
            "Epoch 5/100\n",
            "936/936 [==============================] - 12s 13ms/step - loss: 6.2808 - accuracy: 0.1024\n",
            "Epoch 6/100\n",
            "936/936 [==============================] - 12s 13ms/step - loss: 6.0216 - accuracy: 0.1173\n",
            "Epoch 7/100\n",
            "936/936 [==============================] - 12s 12ms/step - loss: 5.7765 - accuracy: 0.1312\n",
            "Epoch 8/100\n",
            "936/936 [==============================] - 12s 13ms/step - loss: 5.5311 - accuracy: 0.1403\n",
            "Epoch 9/100\n",
            "936/936 [==============================] - 12s 13ms/step - loss: 5.3141 - accuracy: 0.1529\n",
            "Epoch 10/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 5.1057 - accuracy: 0.1647\n",
            "Epoch 11/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 4.9080 - accuracy: 0.1743\n",
            "Epoch 12/100\n",
            "936/936 [==============================] - 13s 13ms/step - loss: 4.7150 - accuracy: 0.1868\n",
            "Epoch 13/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 4.5502 - accuracy: 0.1995\n",
            "Epoch 14/100\n",
            "936/936 [==============================] - 12s 12ms/step - loss: 4.3841 - accuracy: 0.2082\n",
            "Epoch 15/100\n",
            "936/936 [==============================] - 12s 13ms/step - loss: 4.2148 - accuracy: 0.2266\n",
            "Epoch 16/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 4.0578 - accuracy: 0.2379\n",
            "Epoch 17/100\n",
            "936/936 [==============================] - 11s 11ms/step - loss: 3.9256 - accuracy: 0.2502\n",
            "Epoch 18/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 3.7716 - accuracy: 0.2660\n",
            "Epoch 19/100\n",
            "936/936 [==============================] - 12s 12ms/step - loss: 3.6693 - accuracy: 0.2763\n",
            "Epoch 20/100\n",
            "936/936 [==============================] - 12s 12ms/step - loss: 3.5359 - accuracy: 0.2932\n",
            "Epoch 21/100\n",
            "936/936 [==============================] - 12s 13ms/step - loss: 3.4272 - accuracy: 0.3060\n",
            "Epoch 22/100\n",
            "936/936 [==============================] - 12s 13ms/step - loss: 3.3094 - accuracy: 0.3221\n",
            "Epoch 23/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 3.2024 - accuracy: 0.3341\n",
            "Epoch 24/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 3.0975 - accuracy: 0.3478\n",
            "Epoch 25/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 3.0127 - accuracy: 0.3573\n",
            "Epoch 26/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 2.9145 - accuracy: 0.3715\n",
            "Epoch 27/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 2.8228 - accuracy: 0.3863\n",
            "Epoch 28/100\n",
            "936/936 [==============================] - 12s 13ms/step - loss: 2.7315 - accuracy: 0.3985\n",
            "Epoch 29/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 2.6510 - accuracy: 0.4128\n",
            "Epoch 30/100\n",
            "936/936 [==============================] - 11s 11ms/step - loss: 2.5857 - accuracy: 0.4196\n",
            "Epoch 31/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 2.5103 - accuracy: 0.4370\n",
            "Epoch 32/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 2.4615 - accuracy: 0.4435\n",
            "Epoch 33/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 2.3675 - accuracy: 0.4605\n",
            "Epoch 34/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 2.3185 - accuracy: 0.4641\n",
            "Epoch 35/100\n",
            "936/936 [==============================] - 12s 12ms/step - loss: 2.2681 - accuracy: 0.4772\n",
            "Epoch 36/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 2.2210 - accuracy: 0.4861\n",
            "Epoch 37/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 2.1594 - accuracy: 0.4958\n",
            "Epoch 38/100\n",
            "936/936 [==============================] - 12s 12ms/step - loss: 2.1163 - accuracy: 0.5012\n",
            "Epoch 39/100\n",
            "936/936 [==============================] - 12s 12ms/step - loss: 2.0475 - accuracy: 0.5135\n",
            "Epoch 40/100\n",
            "936/936 [==============================] - 12s 12ms/step - loss: 2.0054 - accuracy: 0.5238\n",
            "Epoch 41/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 1.9356 - accuracy: 0.5357\n",
            "Epoch 42/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 1.9061 - accuracy: 0.5426\n",
            "Epoch 43/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 1.8596 - accuracy: 0.5530\n",
            "Epoch 44/100\n",
            "936/936 [==============================] - 13s 14ms/step - loss: 1.8350 - accuracy: 0.5527\n",
            "Epoch 45/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 1.7979 - accuracy: 0.5635\n",
            "Epoch 46/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 1.7463 - accuracy: 0.5715\n",
            "Epoch 47/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 1.7189 - accuracy: 0.5784\n",
            "Epoch 48/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 1.6766 - accuracy: 0.5849\n",
            "Epoch 49/100\n",
            "936/936 [==============================] - 12s 12ms/step - loss: 1.6332 - accuracy: 0.5949\n",
            "Epoch 50/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 1.6174 - accuracy: 0.5990\n",
            "Epoch 51/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 1.5769 - accuracy: 0.6063\n",
            "Epoch 52/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 1.5457 - accuracy: 0.6124\n",
            "Epoch 53/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 1.5169 - accuracy: 0.6203\n",
            "Epoch 54/100\n",
            "936/936 [==============================] - 11s 11ms/step - loss: 1.4830 - accuracy: 0.6267\n",
            "Epoch 55/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 1.4675 - accuracy: 0.6278\n",
            "Epoch 56/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 1.4252 - accuracy: 0.6370\n",
            "Epoch 57/100\n",
            "936/936 [==============================] - 12s 13ms/step - loss: 1.4067 - accuracy: 0.6458\n",
            "Epoch 58/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 1.3579 - accuracy: 0.6494\n",
            "Epoch 59/100\n",
            "936/936 [==============================] - 12s 13ms/step - loss: 1.3422 - accuracy: 0.6565\n",
            "Epoch 60/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 1.3263 - accuracy: 0.6588\n",
            "Epoch 61/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 1.3004 - accuracy: 0.6685\n",
            "Epoch 62/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 1.2872 - accuracy: 0.6691\n",
            "Epoch 63/100\n",
            "936/936 [==============================] - 12s 12ms/step - loss: 1.2678 - accuracy: 0.6727\n",
            "Epoch 64/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 1.2654 - accuracy: 0.6717\n",
            "Epoch 65/100\n",
            "936/936 [==============================] - 11s 11ms/step - loss: 1.2195 - accuracy: 0.6855\n",
            "Epoch 66/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 1.2084 - accuracy: 0.6842\n",
            "Epoch 67/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 1.2000 - accuracy: 0.6878\n",
            "Epoch 68/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 1.1558 - accuracy: 0.6953\n",
            "Epoch 69/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 1.1386 - accuracy: 0.7002\n",
            "Epoch 70/100\n",
            "936/936 [==============================] - 12s 12ms/step - loss: 1.1441 - accuracy: 0.6966\n",
            "Epoch 71/100\n",
            "936/936 [==============================] - 10s 11ms/step - loss: 1.1049 - accuracy: 0.7089\n",
            "Epoch 72/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 1.0884 - accuracy: 0.7132\n",
            "Epoch 73/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 1.0737 - accuracy: 0.7163\n",
            "Epoch 74/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 1.0735 - accuracy: 0.7147\n",
            "Epoch 75/100\n",
            "936/936 [==============================] - 13s 13ms/step - loss: 1.0683 - accuracy: 0.7150\n",
            "Epoch 76/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 1.0214 - accuracy: 0.7255\n",
            "Epoch 77/100\n",
            "936/936 [==============================] - 11s 11ms/step - loss: 1.0366 - accuracy: 0.7202\n",
            "Epoch 78/100\n",
            "936/936 [==============================] - 12s 12ms/step - loss: 1.0118 - accuracy: 0.7288\n",
            "Epoch 79/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 1.0018 - accuracy: 0.7312\n",
            "Epoch 80/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 0.9770 - accuracy: 0.7401\n",
            "Epoch 81/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 0.9749 - accuracy: 0.7377\n",
            "Epoch 82/100\n",
            "936/936 [==============================] - 11s 11ms/step - loss: 0.9715 - accuracy: 0.7398\n",
            "Epoch 83/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 0.9521 - accuracy: 0.7458\n",
            "Epoch 84/100\n",
            "936/936 [==============================] - 12s 12ms/step - loss: 0.9343 - accuracy: 0.7478\n",
            "Epoch 85/100\n",
            "936/936 [==============================] - 12s 12ms/step - loss: 0.9345 - accuracy: 0.7480\n",
            "Epoch 86/100\n",
            "936/936 [==============================] - 12s 12ms/step - loss: 0.9144 - accuracy: 0.7513\n",
            "Epoch 87/100\n",
            "936/936 [==============================] - 12s 12ms/step - loss: 0.9053 - accuracy: 0.7582\n",
            "Epoch 88/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 0.8898 - accuracy: 0.7607\n",
            "Epoch 89/100\n",
            "936/936 [==============================] - 11s 11ms/step - loss: 0.8827 - accuracy: 0.7620\n",
            "Epoch 90/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 0.8593 - accuracy: 0.7652\n",
            "Epoch 91/100\n",
            "936/936 [==============================] - 13s 14ms/step - loss: 0.8583 - accuracy: 0.7673\n",
            "Epoch 92/100\n",
            "936/936 [==============================] - 12s 13ms/step - loss: 0.8502 - accuracy: 0.7667\n",
            "Epoch 93/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 0.8560 - accuracy: 0.7702\n",
            "Epoch 94/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 0.8316 - accuracy: 0.7725\n",
            "Epoch 95/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 0.8360 - accuracy: 0.7748\n",
            "Epoch 96/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 0.8217 - accuracy: 0.7741\n",
            "Epoch 97/100\n",
            "936/936 [==============================] - 12s 13ms/step - loss: 0.8173 - accuracy: 0.7750\n",
            "Epoch 98/100\n",
            "936/936 [==============================] - 11s 12ms/step - loss: 0.7985 - accuracy: 0.7830\n",
            "Epoch 99/100\n",
            "936/936 [==============================] - 12s 13ms/step - loss: 0.7827 - accuracy: 0.7839\n",
            "Epoch 100/100\n",
            "936/936 [==============================] - 12s 12ms/step - loss: 0.7866 - accuracy: 0.7842\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a9431c990c0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/Natural-Language-Processing/LSTM_Generator2')"
      ],
      "metadata": {
        "id": "6UjifhecGbe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word(input_text):\n",
        "    input_text = input_text.lower()\n",
        "    word_tokens = input_text.split()\n",
        "    int_tokens = [vocab_mapping[token] for token in word_tokens]\n",
        "\n",
        "    prediction = model.predict([int_tokens])\n",
        "    prediction_idx = np.argmax(prediction)\n",
        "    return convert_int_to_text([[prediction_idx]], vocab_mapping)[0]\n",
        "\n",
        "\n",
        "def generate_text(input_text, n_words):\n",
        "    word_sequence = input_text.split()\n",
        "    context = word_sequence[:]\n",
        "    for _ in range(n_words):\n",
        "        prediction = predict_next_word(' '.join(context))\n",
        "        word_sequence.append(prediction)\n",
        "        context.append(prediction)\n",
        "        if len(context) > 20:\n",
        "            context.pop(0)\n",
        "\n",
        "    return ' '.join(word_sequence)\n"
      ],
      "metadata": {
        "id": "qlxzfr3CGggk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(\"everyone is living happy\", 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "XJQIfFXAcl-e",
        "outputId": "bd241fc8-73ca-4721-f500-069f7b5e5113"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'everyone is living happy with you and how it has come even my mother'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(\"everyone is living happy\", 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "id": "CSBfl3czcsxQ",
        "outputId": "20ce88f3-e84e-4eaf-b92f-9ec9479d62af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'is living happy with you and how it has come even my mother said that may be away your sight and hearing allah has come over there will come about this beat she'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(\"everyone is living happy today since\", 50)"
      ],
      "metadata": {
        "id": "gk_f6tO9fr6V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 985
        },
        "outputId": "c004b9f6-e1d0-4370-9600-98ef43e2c2fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'everyone is living happy today since you past how does our difference you do what we will go about so bengal if it modi eyes they fabricated it then wont they had done so mumbai does his stand for bible israel along with pure jehovahs discussions to meet his daughter report on the accident of car'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(\"doing politics the back houses a rear camera was it sometime during his prehuman existence at his birth as a\", 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_vempL-mZYPV",
        "outputId": "2fde6644-a752-4d34-feb0-ec095588d50c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "1/1 [==============================] - 0s 102ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 103ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'doing politics the back houses a rear camera was it sometime during his prehuman existence at his birth as a human at his baptism or upon his being resurrected they didnt talk the driver immediately informed the police they have subsequently been expelled from the party to that end we can reflect on some past examples of courage it was the first time something like that was happening in my life i will be sending a letter to the cm in this regard he said the security personnel were caught off guard where is achhe din which way will you go in it became part of the mission san gabriel arcngel and then the rancho san gorgonio he was speaking'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(\"The people around the world gathered\", 200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ALzGajWvZySU",
        "outputId": "f18c2b9d-4964-44ce-a63e-3b4dda369f64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 89ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 95ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 86ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The people around the world gathered on the day of judgment hindi film actor mahesh anand passes away another passenger suffered injuries in the mishap and why are despoiling and violence in front of me and why does quarreling occur and why is strife carried this approach has to change then there was violence meditation will be helpful to have peace of mind the couple are parents to an eightyear old daughter police is investigating into the matter the central delhi has by social media the issue has given its district and any lord i turn away from the students the students has not released on this hospital for beneficial for the country the construction of these roads is underway the turbopetrol is likely to get a sevenspeed dct auto option a decision on this will be taken in our next meeting enter your details that is our thinking his voice was wobbling they have perfected that urgent investigation you make the night to enter into the day and you make the day to enter into the night ie increase and decrease in the hours of the night and the day during winter and summer you bring the living out of the dead and you bring'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Im6765liawnJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}